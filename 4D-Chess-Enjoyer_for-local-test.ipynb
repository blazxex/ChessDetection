{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_-qRK7rUtQU"
   },
   "source": [
    "# Full pipeline by Senor Army Junior Paopeaw Faith Jeanz (We are just a chill guy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xi9ZJ96CSDZh"
   },
   "source": [
    "# Import Lib and file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:55:03.592953Z",
     "iopub.status.busy": "2024-12-12T09:55:03.592570Z",
     "iopub.status.idle": "2024-12-12T09:55:19.939593Z",
     "shell.execute_reply": "2024-12-12T09:55:19.938490Z",
     "shell.execute_reply.started": "2024-12-12T09:55:03.592922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:31:19.828063Z",
     "iopub.status.busy": "2024-12-12T09:31:19.827231Z",
     "iopub.status.idle": "2024-12-12T09:31:23.603471Z",
     "shell.execute_reply": "2024-12-12T09:31:23.602614Z",
     "shell.execute_reply.started": "2024-12-12T09:31:19.828009Z"
    },
    "id": "9lgUl7epIzpi",
    "outputId": "ba92aeea-2d95-4d6f-e622-de661e4dcfe0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "Setup complete âœ… (16 CPUs, 15.5 GB RAM, 117.3/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR TA's LOCAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:31:30.020108Z",
     "iopub.status.busy": "2024-12-12T09:31:30.019656Z",
     "iopub.status.idle": "2024-12-12T09:31:30.025100Z",
     "shell.execute_reply": "2024-12-12T09:31:30.024260Z",
     "shell.execute_reply.started": "2024-12-12T09:31:30.020076Z"
    },
    "id": "wu4hyETj0aho",
    "outputId": "e463e4c2-809c-4306-dfb0-bae179302b74",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/weights/yolo8-20epoch.pt\n"
     ]
    }
   ],
   "source": [
    "chess_model = \"/weights/yolo8-20epoch.pt\"\n",
    "hand_model = \"/weights/Hand-yolo.pt\"\n",
    "\n",
    "#IF no dataset\n",
    "\n",
    "#set your dataset root\n",
    "#should look something like dataset_root = './Chess Detection Competition' \n",
    "\n",
    "#path to a video\n",
    "# /home/jaf/ChessDetection/Chess Detection Competition/test_videos/2_Move_rotate_student.mp4\n",
    "dataset_root = '/kaggle/input/'\n",
    "\n",
    "\n",
    "print(chess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:31.614578Z",
     "iopub.status.busy": "2024-12-12T09:35:31.614218Z",
     "iopub.status.idle": "2024-12-12T09:35:32.733527Z",
     "shell.execute_reply": "2024-12-12T09:35:32.732613Z",
     "shell.execute_reply.started": "2024-12-12T09:35:31.614549Z"
    },
    "id": "lgCJJWCgMOSf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import operator\n",
    "import sys\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "import scipy.cluster as clstr\n",
    "\n",
    "import heapq\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import chess\n",
    "import chess.pgn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7q_kM9tFbeG"
   },
   "source": [
    "# Final PipeLine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXT_qQPqKleZ"
   },
   "source": [
    "## Pre Process Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:34.977627Z",
     "iopub.status.busy": "2024-12-12T09:35:34.977081Z",
     "iopub.status.idle": "2024-12-12T09:35:34.991552Z",
     "shell.execute_reply": "2024-12-12T09:35:34.990637Z",
     "shell.execute_reply.started": "2024-12-12T09:35:34.977595Z"
    },
    "id": "aySOHIOJLXo1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getGreenMask(rgb_image):\n",
    "    hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)  # Convert to HSV color space\n",
    "\n",
    "    # Define the green color range in HSV\n",
    "    lower_green = np.array([40, 20, 30])  # Lower bound of green\n",
    "    upper_green = np.array([100, 255,200])  # Upper bound of green\n",
    "\n",
    "    # Create a mask for green color\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    kernel = np.ones((20,20), np.uint8)\n",
    "    green_mask_= cv2.morphologyEx(green_mask,cv2.MORPH_OPEN, kernel,10)\n",
    "    green_mask= cv2.erode(green_mask, kernel,3)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    green_detected = cv2.bitwise_and(rgb_image, rgb_image, mask=green_mask)\n",
    "\n",
    "    return green_mask, green_detected\n",
    "\n",
    "\n",
    "def GetCorner(binary_img):\n",
    "    x_indices, y_indices = np.where(binary_img == 255)\n",
    "\n",
    "    # # Get the min and max positions for x and y\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "\n",
    "    # print(f\"Min X: {x_min}, Max X: {x_max}\")\n",
    "    # print(f\"Min Y: {y_min}, Max Y: {y_max}\")\n",
    "    return x_min,y_min,x_max,y_max\n",
    "\n",
    "def CropAndPadding(rgb_image, binary_image, padd,x_min,y_min,x_max,y_max):\n",
    "    # plt.imshow(binary_image)\n",
    "    # plt.show()\n",
    "    st_crop = binary_image[x_min:x_max,y_min:y_max]\n",
    "    # plt.imshow(st_crop)\n",
    "    # plt.show()\n",
    "    # print(x_min,y_min,x_max,y_max)\n",
    "\n",
    "    w,h = rgb_image.shape[:2];\n",
    "    x_min_padd = max(0, x_min-padd)\n",
    "    x_max_padd = min(w, x_max+padd)\n",
    "    y_min_padd = max(0, y_min-padd)\n",
    "    y_max_padd = min(h, y_max+padd)\n",
    "\n",
    "    # rgb_crop = rgb[x_min:x_max,y_min:y_max,:]\n",
    "    rgb_crop = rgb_image[x_min_padd:x_max_padd,y_min_padd:y_max_padd,:]\n",
    "    return rgb_crop\n",
    "\n",
    "def rotateImageBasedOnBlackPiece(rgb_image):\n",
    "    hsv = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)  # Convert to HSV color space\n",
    "\n",
    "    # Define the green color range in HSV\n",
    "    lower_black = np.array([0, 0, 0])  # Lower bound of green\n",
    "    upper_black = np.array([180, 50,100])  # Upper bound of green\n",
    "\n",
    "    # Create a mask for green color\n",
    "    black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "    # kernel for cleaning mask\n",
    "    close_kernel = np.ones((10,10), np.uint8)\n",
    "    ero_kernel = np.ones((8,8), np.uint8)\n",
    "\n",
    "    # cleaning mask\n",
    "    black_mask = cv2.morphologyEx(black_mask,cv2.MORPH_CLOSE, close_kernel)\n",
    "    black_mask= cv2.erode(black_mask, close_kernel,20)\n",
    "\n",
    "\n",
    "    # Output\n",
    "    output = cv2.connectedComponentsWithStats(black_mask, 8, cv2.CV_32S)\n",
    "\n",
    "    num_count = output[0]-1\n",
    "    stat = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    counts = [0,0,0,0] # down, right, up, left\n",
    "    image_height = rgb_image.shape[0]\n",
    "    image_width = rgb_image.shape[1]\n",
    "    for i in range(len(centroids)):\n",
    "        center_x, center_y = int(centroids[i][0]), int(centroids[i][1])\n",
    "        if(center_y >= image_height/2):\n",
    "            counts[0] += 1;\n",
    "        else:\n",
    "            counts[2] += 1;\n",
    "        if(center_x >= image_width/2):\n",
    "            counts[3] += 1;\n",
    "        else:\n",
    "            counts[1] += 1;\n",
    "\n",
    "    m = np.argmax(counts)\n",
    "    # print(f'rotation:{m}')\n",
    "    return m\n",
    "    # rotate_image = np.rot90(rgb_image, m) ## counter clock wise\n",
    "    # # return green_mask, green_detected\n",
    "    # return rotate_image;\n",
    "class HandDetector:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def IsFoundPerson(self, results):\n",
    "        for det in results[0].boxes:\n",
    "            cls = int(det.cls)\n",
    "            if cls == 0:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def predict(self, image):\n",
    "        results = self.model.predict(image,verbose=False)\n",
    "        return self.IsFoundPerson(results)  # Use self to call the instance method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:38.120627Z",
     "iopub.status.busy": "2024-12-12T09:35:38.120300Z",
     "iopub.status.idle": "2024-12-12T09:35:38.145516Z",
     "shell.execute_reply": "2024-12-12T09:35:38.144794Z",
     "shell.execute_reply.started": "2024-12-12T09:35:38.120600Z"
    },
    "id": "jgc76LqtKjts",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_image(img, title=\"Image\"):\n",
    "    \"\"\"Display an image using matplotlib.\"\"\"\n",
    "    if len(img.shape) == 2:  # Grayscale image\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:  # Color image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def canny(img):\n",
    "    # Compute the median intensity of the already blurred image\n",
    "    # Use Otsu's method to determine a global threshold\n",
    "    otsu_threshold, _ = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Compute lower and upper thresholds for Canny\n",
    "    lower_threshold = max(0, int(0.5 * otsu_threshold))\n",
    "    upper_threshold = min(255, int(otsu_threshold))\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(img, lower_threshold, upper_threshold)\n",
    "    return edges\n",
    "\n",
    "\n",
    "\n",
    "def hough_lines(img):\n",
    "    rho, theta, thresh = 2, np.pi / 180, 600\n",
    "    return cv2.HoughLines(img, rho, theta, thresh)\n",
    "\n",
    "\n",
    "def sort_lines(lines):\n",
    "    \"\"\"\n",
    "    Sorts lines by horizontal and vertical\n",
    "    \"\"\"\n",
    "    h = []\n",
    "    v = []\n",
    "    for i in range(lines.shape[0]):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        if theta < np.pi / 4 or theta > np.pi - np.pi / 4:\n",
    "            v.append([rho, theta])\n",
    "        else:\n",
    "            h.append([rho, theta])\n",
    "    return h, v\n",
    "\n",
    "\n",
    "def calculate_intersections(h, v):\n",
    "    \"\"\"\n",
    "    Finds the intersection of two lines given in Hesse normal form.\n",
    "    See https://stackoverflow.com/a/383527/5087436\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    for rho1, theta1 in h:\n",
    "        for rho2, theta2 in v:\n",
    "            A = np.array([\n",
    "                [np.cos(theta1), np.sin(theta1)],\n",
    "                [np.cos(theta2), np.sin(theta2)]\n",
    "            ])\n",
    "            b = np.array([[rho1], [rho2]])\n",
    "            point = np.linalg.solve(A, b)\n",
    "            point = int(np.round(point[0])), int(np.round(point[1]))\n",
    "            points.append(point)\n",
    "    return np.array(points)\n",
    "\n",
    "\n",
    "def cluster_intersections(points, max_dist=40):\n",
    "    # I want to change this to kmeans\n",
    "    Y = spatial.distance.pdist(points)\n",
    "    Z = clstr.hierarchy.single(Y)\n",
    "    T = clstr.hierarchy.fcluster(Z, max_dist, 'distance')\n",
    "    clusters = defaultdict(list)\n",
    "    for i in range(len(T)):\n",
    "        clusters[T[i]].append(points[i])\n",
    "    clusters = clusters.values()\n",
    "    clusters = map(lambda arr: (np.mean(np.array(arr)[:, 0]), np.mean(np.array(arr)[:, 1])), clusters)\n",
    "\n",
    "    result = []\n",
    "    for point in clusters:\n",
    "        result.append([point[0], point[1]])\n",
    "    sorted_result = sorted(result, key=lambda pair: (pair[0], pair[1]))\n",
    "    outlier_removal_result = filter_chessboard_coordinates(sorted_result)\n",
    "    return outlier_removal_result\n",
    "\n",
    "\n",
    "def find_chessboard_corners(points):\n",
    "    \"\"\"\n",
    "    Code from https://medium.com/@neshpatel/solving-sudoku-part-ii-9a7019d196a2\n",
    "    \"\"\"\n",
    "    # Bottom-right point has the largest (x + y) value\n",
    "    # Top-left has point smallest (x + y) value\n",
    "    # Bottom-left point has smallest (x - y) value\n",
    "    # Top-right point has largest (x - y) value\n",
    "    bottom_right, _ = max(enumerate([pt[0] + pt[1] for pt in points]), key=operator.itemgetter(1))\n",
    "    top_left, _ = min(enumerate([pt[0] + pt[1] for pt in points]), key=operator.itemgetter(1))\n",
    "    bottom_left, _ = min(enumerate([pt[0] - pt[1] for pt in points]), key=operator.itemgetter(1))\n",
    "    top_right, _ = max(enumerate([pt[0] - pt[1] for pt in points]), key=operator.itemgetter(1))\n",
    "    return [points[top_left], points[top_right], points[bottom_left], points[bottom_right]]\n",
    "\n",
    "\n",
    "def distance_between(p1, p2):\n",
    "    \"\"\"\n",
    "    Code from https://medium.com/@neshpatel/solving-sudoku-part-ii-9a7019d196a2\n",
    "    \"\"\"\n",
    "    a = p2[0] - p1[0]\n",
    "    b = p2[1] - p1[1]\n",
    "    return np.sqrt((a ** 2) + (b ** 2))\n",
    "\n",
    "\n",
    "def warp_image(img, edges):\n",
    "    \"\"\"\n",
    "    Code from https://medium.com/@neshpatel/solving-sudoku-part-ii-9a7019d196a2\n",
    "    \"\"\"\n",
    "    top_left, top_right, bottom_left, bottom_right = edges[0], edges[1], edges[2], edges[3]\n",
    "\n",
    "    # Explicitly set the data type to float32 or 'getPerspectiveTransform' will throw an error\n",
    "    warp_src = np.array([top_left, top_right, bottom_right, bottom_left], dtype='float32')\n",
    "\n",
    "    side = max([\n",
    "        distance_between(bottom_right, top_right),\n",
    "        distance_between(top_left, bottom_left),\n",
    "        distance_between(bottom_right, bottom_left),\n",
    "        distance_between(top_left, top_right)\n",
    "    ])\n",
    "\n",
    "    # Describe a square with side of the calculated length, this is the new perspective we want to warp to\n",
    "    warp_dst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], dtype='float32')\n",
    "\n",
    "    # Gets the transformation matrix for skewing the image to fit a square by comparing the 4 before and after points\n",
    "    m = cv2.getPerspectiveTransform(warp_src, warp_dst)\n",
    "    # print(f'warped transform matrix: {m}')\n",
    "\n",
    "    # Performs the transformation on the original image\n",
    "    return cv2.warpPerspective(img, m, (int(side), int(side)))\n",
    "\n",
    "\n",
    "def cut_chessboard(img, output_path, output_prefix=\"\"):\n",
    "    side_len = int(img.shape[0] / 8)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            tile = img[i * side_len: (i + 1) * side_len, j * side_len: (j + 1) * side_len]\n",
    "            cv2.imwrite(output_path + output_prefix + \"-\" + str(j + i * 8) + \".jpg\", tile)\n",
    "\n",
    "\n",
    "def resize_image(img):\n",
    "    \"\"\"\n",
    "    Resizes image to a maximum width of 800px\n",
    "    \"\"\"\n",
    "    return cv2.resize(img, (800, 800))\n",
    "    # else:\n",
    "    #     return img\n",
    "def save_clustered_to_csv(clustered, filename=\"clustered_intersections.csv\"):\n",
    "    # Convert clustered data into a DataFrame\n",
    "    df = pd.DataFrame(clustered, columns=[\"x\", \"y\"])\n",
    "    # Save DataFrame to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Clustered intersections saved to {filename}\")\n",
    "\n",
    "\n",
    "def render_lines(img, lines, color):\n",
    "    for rho, theta in lines:\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0, y0 = a * rho, b * rho\n",
    "        pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * a))\n",
    "        pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * a))\n",
    "        cv2.line(img, pt1, pt2, color, 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def render_intersections(img, points, color, size):\n",
    "    for point in points:\n",
    "        cv2.circle(img, (int(point[0]), int(point[1])), 2, color, size)\n",
    "\n",
    "def find_3_closest(clustered):\n",
    "    # Find the reference point\n",
    "    ref_point = min(clustered, key=lambda pair: (pair[0], -pair[1]))\n",
    "\n",
    "    # Helper function to calculate Euclidean distance\n",
    "    def distance(point):\n",
    "        return math.sqrt((point[0] - ref_point[0])**2 + (point[1] - ref_point[1])**2)\n",
    "\n",
    "    # Filter out the reference point and find the 3 closest points\n",
    "    filtered_points = [point for point in clustered if point != ref_point]\n",
    "    closest_points = heapq.nsmallest(3, filtered_points, key=distance)\n",
    "\n",
    "    return ref_point, closest_points\n",
    "def filter_chessboard_coordinates(coordinates):\n",
    "    \"\"\"\n",
    "    Filters the given chessboard intersection points to ensure there are exactly 81 points.\n",
    "\n",
    "    Args:\n",
    "        coordinates (list of list): A list of [x, y] coordinates.\n",
    "\n",
    "    Returns:\n",
    "        list of list: A filtered list of 81 coordinates as [x, y].\n",
    "    \"\"\"\n",
    "    filtered_coordinates = coordinates\n",
    "\n",
    "    if len(coordinates) > 81:\n",
    "      coordinates = np.array(coordinates)  # Convert input coordinates to a numpy array\n",
    "\n",
    "      # Perform K-means clustering to group points into 81 clusters\n",
    "      kmeans = KMeans(n_clusters=81, random_state=42)\n",
    "      kmeans.fit(coordinates)\n",
    "      cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "      # Convert the cluster centers to rounded coordinates and return as a list of lists\n",
    "      filtered_coordinates = np.round(cluster_centers, decimals=2).tolist()\n",
    "\n",
    "    return filtered_coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:42.936712Z",
     "iopub.status.busy": "2024-12-12T09:35:42.936026Z",
     "iopub.status.idle": "2024-12-12T09:35:42.947345Z",
     "shell.execute_reply": "2024-12-12T09:35:42.946469Z",
     "shell.execute_reply.started": "2024-12-12T09:35:42.936671Z"
    },
    "id": "DiFm2eraGfEU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_chessboard(src, debug=False):\n",
    "    # src = cv2.imread(src_path)\n",
    "\n",
    "    # if src is None:\n",
    "    #     sys.exit(\"There is no file with this path!\")\n",
    "\n",
    "    # src = resize_image(src)\n",
    "    # src_copy = src.copy()\n",
    "\n",
    "    # # Convert to grayscale\n",
    "    # process = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    src = src\n",
    "    src_copy = src.copy()\n",
    "    process = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if debug:\n",
    "        show_image(src_copy, title=f'src img{src_copy.shape}')\n",
    "        show_image(process, title=f'gray process imgae{process.shape}')\n",
    "        # cv2.imwrite('grayscale.png', process)\n",
    "\n",
    "    # Blur to remove disturbing things\n",
    "    # process = cv2.blur(process, (4, 4))\n",
    "    #process = cv2.medianBlur(process, 5)\n",
    "    process = cv2.GaussianBlur(process, (5, 5), 0) #GaussianBlur give a better result\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        show_image(process, title=f'blur process imgae{process.shape}')\n",
    "\n",
    "        # cv2.imwrite('blur.png', process)\n",
    "\n",
    "    # Use Canny Edge Detector\n",
    "    process = canny(process)\n",
    "\n",
    "    if debug:\n",
    "        show_image(process, title=f'canny process imgae{process.shape}')\n",
    "        # cv2.imwrite('canny.png', process)\n",
    "\n",
    "    # Dilate image (thicker lines)\n",
    "    process = cv2.dilate(process, np.ones((3, 3), dtype=np.uint8))\n",
    "\n",
    "    if debug:\n",
    "        show_image(process, title=f'dialate process imgae{process.shape}')\n",
    "        # cv2.imwrite('dilate.png', process)\n",
    "\n",
    "    # Use Hough transform to detect lines\n",
    "    lines = hough_lines(process)\n",
    "\n",
    "    # Sort lines by horizontal and vertical\n",
    "    h, v = sort_lines(lines)\n",
    "\n",
    "    if debug:\n",
    "        render_lines(src_copy, h, (0, 255, 0))\n",
    "        render_lines(src_copy, v, (0, 0, 255))\n",
    "        show_image(src_copy, title=\"Sorted Lines\")\n",
    "        # cv2.imwrite('sorted-lines.png', src_copy)\n",
    "\n",
    "    if len(h) < 9 or len(v) < 9:\n",
    "        print(\"There are not enough horizontal and vertical lines in this image. Try it anyway!\")\n",
    "\n",
    "    # Calculate intersections of the horizontal and vertical lines\n",
    "    intersections = calculate_intersections(h, v)\n",
    "\n",
    "    if debug:\n",
    "        render_intersections(src_copy, intersections, (255, 0, 0), 1)\n",
    "        show_image(src_copy, title=\"Intersections\")\n",
    "        # cv2.imwrite('intersections.png', src_copy)\n",
    "\n",
    "    # Cluster intersection since there are many\n",
    "    clustered = cluster_intersections(intersections)\n",
    "    filtered_clustered = filter_chessboard_coordinates(clustered)\n",
    "\n",
    "    if debug:\n",
    "        src_copy = src.copy()\n",
    "        render_intersections(src_copy, clustered, (255, 0, 0), 5)\n",
    "        show_image(src_copy, title=\"Clustered Intersections\")\n",
    "        print(clustered)\n",
    "        save_clustered_to_csv(clustered)\n",
    "        result = min(clustered, key=lambda pair: (pair[0], -pair[1]))\n",
    "        if result:\n",
    "          print(f'corner: {result}')\n",
    "          # print(find_3_closest(clustered))\n",
    "          # results2 = is_black_or_white_with_visualization(src_path, find_3_closest(clustered), 10, 128)\n",
    "          # print(results2)\n",
    "\n",
    "\n",
    "        # cv2.imwrite('clustered-intersections.png', src_copy)\n",
    "\n",
    "    if len(clustered) != 81:\n",
    "        print(\"Something is wrong. There are \" + str(len(intersections)) + \" instead of 81 intersections.\")\n",
    "\n",
    "    # Find outer corners of sas chessboard\n",
    "    corners = find_chessboard_corners(clustered)\n",
    "\n",
    "    if debug:\n",
    "        src_copy = src.copy()\n",
    "        render_intersections(src_copy, corners, (255, 0, 0), 5)\n",
    "        show_image(src_copy, title=\"Corners\")\n",
    "        # cv2.imwrite('corners.png', src_copy)\n",
    "\n",
    "    # Warp and crop image\n",
    "    # dst = warp_image(src, corners)\n",
    "    # dst = resize_image(dst)\n",
    "    return corners,filtered_clustered\n",
    "\n",
    "    if debug:\n",
    "        show_image(dst, title=f'warped process imgae{dst.shape}')\n",
    "        # cv2.imwrite('warped.png', dst)\n",
    "\n",
    "    # Cut chessboard into 64 tiles\n",
    "    # cut_chessboard(dst, output_path, output_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:46.287099Z",
     "iopub.status.busy": "2024-12-12T09:35:46.286756Z",
     "iopub.status.idle": "2024-12-12T09:35:46.295834Z",
     "shell.execute_reply": "2024-12-12T09:35:46.294894Z",
     "shell.execute_reply.started": "2024-12-12T09:35:46.287070Z"
    },
    "id": "pAqi5BROINrh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "class YOLOPredictor:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"\n",
    "        Initialize the YOLO model.\n",
    "\n",
    "        :param model_path: Path to the trained YOLO model.\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        \n",
    "        self.class_names = [\n",
    "            \"black-bishop\",\n",
    "            \"black-king\",\n",
    "            \"black-knight\",\n",
    "            \"black-pawn\",\n",
    "            \"black-queen\",\n",
    "            \"black-rook\",\n",
    "            \"white-bishop\",\n",
    "            \"white-king\",\n",
    "            \"white-knight\",\n",
    "            \"white-pawn\",\n",
    "            \"white-queen\",\n",
    "            \"white-rook\",\n",
    "        ]\n",
    "        \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Predict bounding boxes for the given image and return in the specified format.\n",
    "\n",
    "        :param image_path: Path to the image for prediction.\n",
    "        :return: List of bounding boxes in the format [class_number, class_name, x, y, width, height, conf]\n",
    "        \"\"\"\n",
    "        results = self.model.predict(image_path)\n",
    "        bbox_list = []\n",
    "\n",
    "        for result in results:\n",
    "            # Get image dimensions\n",
    "            w, h, _ = result.orig_img.shape\n",
    "\n",
    "            # Iterate through detections in each result\n",
    "            for det in result.boxes:\n",
    "                # Get normalized xywh (YOLO format) and class confidence\n",
    "                x_center, y_center, width, height = det.xywhn[0]\n",
    "                conf = det.conf.item()  # Convert the tensor to a float value\n",
    "                cls = int(det.cls)  # Class number\n",
    "\n",
    "                # Denormalize to pixel values\n",
    "                x_center_pixel = int(x_center * w)\n",
    "                y_center_pixel = int(y_center * h)\n",
    "                width_pixel = int(width * w)\n",
    "                height_pixel = int(height * h)\n",
    "\n",
    "                # Calculate starting point (top-left corner) of the bounding box\n",
    "                x = int(x_center_pixel - width_pixel / 2)\n",
    "                y = int(y_center_pixel - height_pixel / 2)\n",
    "\n",
    "                # Get class name from class_names\n",
    "                class_name = self.class_names[cls]\n",
    "\n",
    "                # Append to the list in the format [class_number, class_name, x, y, width, height, conf]\n",
    "                bbox_list.append([cls, class_name, x, y, width_pixel, height_pixel, conf])\n",
    "\n",
    "        return bbox_list\n",
    "\n",
    "\n",
    "def objectDetection(img_path,model_path):\n",
    "\n",
    "  predictor = YOLOPredictor(model_path)\n",
    "  predictor.conf = 0.50\n",
    "  bbox_list = predictor.predict(img_path)\n",
    "  return bbox_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c6Efr2pIJEFl",
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def printBoundingBox(bbox_list, count):\n",
    "    print(f'==========================={count}======================================')\n",
    "\n",
    "    # result = []\n",
    "    # for classNumber, className, x, y, w, h, conf in bbox_list:\n",
    "    #     result.append([className,classNumber, x, y, w, h, conf])\n",
    "\n",
    "    # # Print the entire list in the desired format\n",
    "    # print(result)\n",
    "    for classNumber, className, x, y, w, h, conf in bbox_list:\n",
    "      print(f'{className} {conf}')\n",
    "    # return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:49.980721Z",
     "iopub.status.busy": "2024-12-12T09:35:49.979856Z",
     "iopub.status.idle": "2024-12-12T09:35:49.986794Z",
     "shell.execute_reply": "2024-12-12T09:35:49.985833Z",
     "shell.execute_reply.started": "2024-12-12T09:35:49.980683Z"
    },
    "id": "Smi2afdqpISs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_bounding_boxes(warped_resize_rotated_image, boundingBox):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on a given image.\n",
    "\n",
    "    Parameters:\n",
    "    - warped_resize_rotated_image: np.ndarray\n",
    "        The image on which to draw the bounding boxes.\n",
    "    - boundingBox: list of lists\n",
    "        Each inner list contains [cls, class_name, x, y, width_pixel, height_pixel, conf].\n",
    "    \"\"\"\n",
    "    # Plot the image\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(warped_resize_rotated_image)\n",
    "\n",
    "    # Plot bounding boxes\n",
    "    for bbox in boundingBox:\n",
    "        _, class_name, x, y, width, height, conf = bbox\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), width, height,\n",
    "            linewidth=2, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add label text\n",
    "        label = f\"{class_name} ({conf:.2f})\"\n",
    "        ax.text(\n",
    "            x, y - 5, label,\n",
    "            color='white', fontsize=12,\n",
    "            bbox=dict(facecolor='red', alpha=0.5, edgecolor='none')\n",
    "        )\n",
    "\n",
    "    # Hide axis for better visualization\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZYHVHDsq-xC"
   },
   "source": [
    "## Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:47:03.249829Z",
     "iopub.status.busy": "2024-12-12T09:47:03.249407Z",
     "iopub.status.idle": "2024-12-12T09:47:03.268345Z",
     "shell.execute_reply": "2024-12-12T09:47:03.267523Z",
     "shell.execute_reply.started": "2024-12-12T09:47:03.249796Z"
    },
    "id": "oVDoX1Loq-Jg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PIECE_MAP = {\n",
    "    0: \"b\", 1: \"k\", 2: \"n\", 3: \"p\", 4: \"q\", 5: \"r\",\n",
    "    6: \"B\", 7: \"K\", 8: \"N\", 9: \"P\", 10: \"Q\", 11: \"R\",\n",
    "}\n",
    "def detection_to_chess_coordinates(objects):\n",
    "    # Constants\n",
    "    CELL_SIZE = 100\n",
    "    GRID_SIZE = 8  # 8x8 chessboard\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for obj in objects:\n",
    "        class_no,class_name ,  x, y, w, h, confidence = obj\n",
    "        # Calculate the top of the chess piece\n",
    "        bottom_y = y + (h * 0.75)\n",
    "        right_x = x + (w * 0.5)\n",
    "\n",
    "        # Calculate the cell (i, j)\n",
    "        i = min(max(int(bottom_y // CELL_SIZE), 0), GRID_SIZE - 1)  # Ensure i is within [0, 7]\n",
    "        j = min(max(int(right_x // CELL_SIZE), 0), GRID_SIZE - 1)      # Ensure j is within [0, 7]\n",
    "\n",
    "        # Append the result\n",
    "        result.append([class_no, i, j])\n",
    "\n",
    "    return result\n",
    "\n",
    "def create_board(chess_coordinates):\n",
    "    board = chess.Board()\n",
    "    board.clear()  # Clear the default starting position\n",
    "\n",
    "    # Place pieces based on the coordinates\n",
    "    for class_no, i, j in chess_coordinates:\n",
    "        piece = chess.Piece.from_symbol(PIECE_MAP[class_no])\n",
    "        square = chess.square(7 - j, i)  # Convert (i, j) to a chess square\n",
    "        board.set_piece_at(square, piece)\n",
    "\n",
    "    return board\n",
    "\n",
    "\n",
    "def boards_to_pgn_move(prev_board, next_board, override_turn = False, override_rule = False):\n",
    "    # Detect the move by comparing squares\n",
    "    move = None\n",
    "\n",
    "    start_list = collections.deque()\n",
    "    destination_list = []\n",
    "    move_count = 0\n",
    "    for square in chess.SQUARES:\n",
    "        prev_piece = prev_board.piece_at(square)\n",
    "        next_piece = next_board.piece_at(square)\n",
    "        if prev_piece != next_piece:\n",
    "            # print(prev_piece, next_piece)\n",
    "            move_count += 1\n",
    "            if prev_piece and next_piece == None:  # Piece moved from this square\n",
    "                if(prev_piece.piece_type == chess.KING):\n",
    "                    start_list.appendleft((prev_piece,square))\n",
    "                else:\n",
    "                    start_list.append((prev_piece,square))\n",
    "            elif next_piece:  # Piece moved to this square\n",
    "                if(prev_piece == None): # Move\n",
    "                    destination_list.append((next_piece,square,False))\n",
    "                elif(prev_piece.color != next_piece.color): # Capture\n",
    "                    destination_list.append((next_piece,square,True))\n",
    "\n",
    "    is_move = False\n",
    "    out = \"\"\n",
    "    misc = []\n",
    "    for piece_from, pos_from in start_list:\n",
    "        for piece_to, pos_to,is_capture in destination_list:\n",
    "            if(piece_from == piece_to):\n",
    "                move = chess.Move(pos_from, pos_to)\n",
    "                misc = [piece_from.color]\n",
    "                # print(prev_board.legal_moves)\n",
    "                print(piece_from, pos_from, pos_to)\n",
    "                if(override_turn):\n",
    "                    prev_board.turn = piece_from.color\n",
    "\n",
    "                # Check for castling\n",
    "                if prev_board.is_kingside_castling(move):\n",
    "                    is_move = True\n",
    "                    out = \"O-O\"\n",
    "                    return is_move, out, misc\n",
    "                elif prev_board.is_queenside_castling(move):\n",
    "                    is_move = True\n",
    "                    out = \"O-O-O\"\n",
    "                    return is_move, out, misc\n",
    "\n",
    "                # if(prev_board.is_pseudo_legal(move)):\n",
    "                if(prev_board.is_legal(move) or override_rule):\n",
    "                    game = chess.pgn.Game()\n",
    "                    game.setup(prev_board)\n",
    "                    game.add_main_variation(move)\n",
    "                    is_move = True\n",
    "                    out = str(game.variation(0)).split()[1]\n",
    "                    return is_move, out, misc\n",
    "\n",
    "    return is_move, out, misc\n",
    "\n",
    "def frames_to_pgn_movelist(frames):\n",
    "    boards = []\n",
    "\n",
    "    for frame in frames:\n",
    "        chess_coordinates = detection_to_chess_coordinates(frame)\n",
    "        boards.append(create_board(chess_coordinates))\n",
    "\n",
    "    pgn_movelist = \"\"\n",
    "\n",
    "    step = 0\n",
    "    game_turn = 1\n",
    "    last_valid_board = None\n",
    "    for board in boards:\n",
    "\n",
    "        if step == 0:\n",
    "            last_valid_board = board\n",
    "            step = 1\n",
    "        else:\n",
    "            is_move, pgn_move, misc = boards_to_pgn_move(last_valid_board, board, override_turn=True,override_rule=True)\n",
    "            last_valid_board = board\n",
    "\n",
    "\n",
    "            if(is_move):\n",
    "                display(chess.svg.board(board, size=200))\n",
    "                if(step % 2 == 0):\n",
    "                    pgn_movelist += pgn_move + \" \"\n",
    "                else:\n",
    "                    if(step == 1 and misc == [chess.BLACK]):\n",
    "                        pgn_movelist += str(game_turn) + \"... \" + pgn_move + \" \"\n",
    "                        step += 1\n",
    "                    else:\n",
    "                        pgn_movelist += str(game_turn) + \". \" + pgn_move + \" \"\n",
    "                    game_turn += 1\n",
    "                step += 1\n",
    "\n",
    "    return pgn_movelist\n",
    "\n",
    "def post_process_pipeline(clip_name, frames):\n",
    "    # clip_name = name of clip (string)\n",
    "    # frames = list of frame\n",
    "    # frame = list of objects (chess piece that is detected in the frame)\n",
    "    # object = [class_number, x, y, width, height]\n",
    "    # x = middle of object horizontal position\n",
    "    # y = middle of object vertical position\n",
    "    # assumptions: image size = 800 px --> x 0-100 = chess column 1\n",
    "        # Class number definitions:\n",
    "        #     \"0: white-queen\",\n",
    "        #     \"1: white-pawn\",\n",
    "        #     \"2: black-rook\",\n",
    "        #     \"3: black-bishop\",\n",
    "        #     \"4: black-knight\",\n",
    "        #     \"5: black-queen\",\n",
    "        #     \"6: black-pawn\",\n",
    "        #     \"7: black-king\",\n",
    "        #     \"8: white-rook\",\n",
    "        #     \"9: white-bishop\",\n",
    "        #     \"10: white-knight\",\n",
    "        #     \"11: white-king\",\n",
    "\n",
    "    pgn_movelist = frames_to_pgn_movelist(frames)\n",
    "    output = [clip_name, pgn_movelist]\n",
    "    return output\n",
    "def export_csv_result(list_of_output, output_path=\"submission.csv\"):\n",
    "    # output = output from post_process_pipeline for each clip\n",
    "\n",
    "    # fix bonus clip name\n",
    "    if(list_of_output[-1][0] == \"Bonus Long Video Label.mp4\"):\n",
    "        list_of_output[-1][0] = \"(Bonus)Long_video_student.mp4\"\n",
    "    \n",
    "    df = pd.DataFrame(list_of_output, columns=[\"row_id\", \"output\"])\n",
    "    # df.to_csv(\"./kaggle/working/submission.csv\", index = False, header = True)\n",
    "    df.to_csv(output_path, index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JamcvnLKMOy0"
   },
   "source": [
    "# Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:35:55.715482Z",
     "iopub.status.busy": "2024-12-12T09:35:55.715086Z",
     "iopub.status.idle": "2024-12-12T09:35:55.726348Z",
     "shell.execute_reply": "2024-12-12T09:35:55.725330Z",
     "shell.execute_reply.started": "2024-12-12T09:35:55.715452Z"
    },
    "id": "8ebip99LMyHm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_video(video_path,frame_per_second,chess_model_path,hand_model_path,Debug):\n",
    "    \"\"\"\n",
    "    Processes a video to extract and analyze frames at specific intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path (str): Path to the video file.\n",
    "    - frame_per_second (int): Number of frames to skip before processing the next one.\n",
    "    \"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    success = True\n",
    "    count = 0\n",
    "    prev_gray = None\n",
    "    x_min, y_min, x_max, y_max = None, None, None, None\n",
    "    rotation_default = None\n",
    "    handDetector = HandDetector(hand_model_path)\n",
    "    bbox_of_each_video = []\n",
    "    frame_after_hand = 0\n",
    "    frame_after_hand_th = 2\n",
    "\n",
    "    while success:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if count % frame_per_second == 0:\n",
    "            isFoundHuman = handDetector.predict(frame)\n",
    "            isPass=False\n",
    "            if(count != 0):\n",
    "                if(isFoundHuman):\n",
    "                    frame_after_hand = 0\n",
    "                if(prev_isFoundHuman and not isFoundHuman):\n",
    "                    frame_after_hand = 1\n",
    "\n",
    "                if(frame_after_hand == frame_after_hand_th):\n",
    "                    isPass=True\n",
    "                frame_after_hand += 1\n",
    "\n",
    "\n",
    "            else:\n",
    "                isPass = True\n",
    "\n",
    "            if(isPass):\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                if count == 0:\n",
    "                    # Initialize cropping values from the first frame\n",
    "                    mask, result_rgb = getGreenMask(rgb.copy())\n",
    "                    x_min, y_min, x_max, y_max = GetCorner(mask)\n",
    "                    rotation_default = rotateImageBasedOnBlackPiece(rgb)\n",
    "                    print(\"Default values initialized for cropping and rotation.\")\n",
    "\n",
    "                mask, _ = getGreenMask(rgb.copy())\n",
    "                rgb_crop = CropAndPadding(rgb, mask, 55, x_min, y_min, x_max, y_max)\n",
    "                if Debug:\n",
    "                    plt.imshow(rgb_crop)\n",
    "                    plt.title(f'rcrop: {count}')\n",
    "                    plt.show()\n",
    "\n",
    "                if count == 0:\n",
    "                  corners,coordinate=process_chessboard(rgb_crop, debug=Debug)\n",
    "                warped = warp_image(rgb_crop, corners)\n",
    "                warped_resize = resize_image(warped)\n",
    "                warped_resize_rotated = np.rot90(warped_resize, rotation_default)\n",
    "                if Debug:\n",
    "                  show_image(warped_resize_rotated, \"model input img\")\n",
    "                boundingBox = objectDetection( warped_resize_rotated  ,chess_model_path)\n",
    "                if Debug:\n",
    "                  printBoundingBox(boundingBox,count) #get input from here to preprocessing process\n",
    "                  plot_bounding_boxes(warped_resize_rotated ,boundingBox)\n",
    "                bbox_of_each_video.append(boundingBox)\n",
    "\n",
    "            prev_frame = frame\n",
    "            prev_isFoundHuman = isFoundHuman\n",
    "        count += 1\n",
    "    return bbox_of_each_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbTn43gqwoI8"
   },
   "source": [
    "## submission code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:47:15.923086Z",
     "iopub.status.busy": "2024-12-12T09:47:15.922362Z",
     "iopub.status.idle": "2024-12-12T09:50:09.862221Z",
     "shell.execute_reply": "2024-12-12T09:50:09.861329Z",
     "shell.execute_reply.started": "2024-12-12T09:47:15.923052Z"
    },
    "id": "aQB837nXu-cP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "csv_output=[]\n",
    "for dirname, _, filenames in os.walk(dataset_root):\n",
    "    for filename in filenames:\n",
    "      if filename.endswith(\".mp4\"):\n",
    "        file_path = os.path.join(dirname, filename)\n",
    "        bbox_of_each_video = process_video(file_path,frame_per_second=30,chess_model_path=chess_model,hand_model_path=hand_model,Debug=False)\n",
    "        csv_output.append(post_process_pipeline(filename,bbox_of_each_video))\n",
    "\n",
    "# bonus_file_flag = False\n",
    "# for (row_id, output) in csv_output:\n",
    "#     if row_id == \"(Bonus)Long_video_student.mp4\":\n",
    "#         bonus_file_flag = True\n",
    "#         break\n",
    "\n",
    "# if not bonus_file_flag:\n",
    "#     csv_output.append([\"(Bonus)Long_video_student.mp4\", \"1. d4 Nf6 2. c4 e6 3. Nf3 d5 4. Nc3 Bb4 5. e3 O-O 6. Bd3 c5 7. O-O dxc4 8. Bxc4 cxd4 9. exd4 Nc6 10. a3 Be7\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T09:41:30.090358Z",
     "iopub.status.busy": "2024-12-12T09:41:30.089421Z",
     "iopub.status.idle": "2024-12-12T09:41:30.101061Z",
     "shell.execute_reply": "2024-12-12T09:41:30.100325Z",
     "shell.execute_reply.started": "2024-12-12T09:41:30.090320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "export_csv_result(csv_output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3AUH_2O03jY8"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9597345,
     "sourceId": 83828,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189466,
     "modelInstanceId": 167147,
     "sourceId": 196033,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189470,
     "modelInstanceId": 167151,
     "sourceId": 196038,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
